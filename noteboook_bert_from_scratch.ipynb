{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building BERT with Pytorch from scratch"
      ],
      "metadata": {
        "id": "kG2XpOKgXBth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T75476lvft-V",
        "outputId": "6db1940b-8849-436c-8dd4-3d587b6d32ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "mLA0wmBpCdO5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the dataset\n",
        "######To prepare dataset, we do next:\n",
        "###### - Split dataset on sentences\n",
        "###### - Create vocabulary for word - token pair, for example {'go': 45}\n",
        "###### - Create training dataset\n",
        "###### - Add special tokens to the sentence\n",
        "###### - Mask 15% of words in the sentence\n",
        "###### - Pad sentence to predefined length\n",
        "###### - Create NSP item from two sentences"
      ],
      "metadata": {
        "id": "0McY06TwGCsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ATdGyuTcP91i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import typing\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as f"
      ],
      "metadata": {
        "id": "WyqIRgz0Qmgq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBBertDataset(Dataset):\n",
        "    # Define Special tokens as attributes of class\n",
        "    CLS = '[CLS]'\n",
        "    PAD = '[PAD]'\n",
        "    SEP = '[SEP]'\n",
        "    MASK = '[MASK]'\n",
        "    UNK = '[UNK]'\n",
        "\n",
        "    MASK_PERCENTAGE = 0.15  # How much words to mask\n",
        "\n",
        "    MASKED_INDICES_COLUMN = 'masked_indices'\n",
        "    TARGET_COLUMN = 'indices'\n",
        "    NSP_TARGET_COLUMN = 'is_next'\n",
        "    TOKEN_MASK_COLUMN = 'token_mask'\n",
        "\n",
        "    OPTIMAL_LENGTH_PERCENTILE = 70\n",
        "\n",
        "    def __init__(self, path, ds_from=None, ds_to=None, should_include_text=False):\n",
        "        self.ds: pd.Series = pd.read_csv(path, engine='python')['review']\n",
        "\n",
        "        if ds_from is not None or ds_to is not None:\n",
        "            self.ds = self.ds[ds_from:ds_to]\n",
        "\n",
        "        self.tokenizer = get_tokenizer('basic_english')\n",
        "        self.counter = Counter()\n",
        "        self.vocab = None\n",
        "\n",
        "        self.optimal_sentence_length = None\n",
        "        self.should_include_text = should_include_text\n",
        "\n",
        "        if should_include_text:\n",
        "            self.columns = ['masked_sentence', self.MASKED_INDICES_COLUMN, 'sentence', self.TARGET_COLUMN,\n",
        "                            self.TOKEN_MASK_COLUMN,\n",
        "                            self.NSP_TARGET_COLUMN]\n",
        "        else:\n",
        "            self.columns = [self.MASKED_INDICES_COLUMN, self.TARGET_COLUMN, self.TOKEN_MASK_COLUMN,\n",
        "                            self.NSP_TARGET_COLUMN]\n",
        "        self.df = self.prepare_dataset()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.df.iloc[idx]\n",
        "\n",
        "        inp = torch.Tensor(item[self.MASKED_INDICES_COLUMN]).long()\n",
        "        token_mask = torch.Tensor(item[self.TOKEN_MASK_COLUMN]).bool()\n",
        "\n",
        "        attention_mask = (inp == self.vocab[self.PAD]).unsqueeze(0)\n",
        "\n",
        "        # NSP target\n",
        "        if item[self.NSP_TARGET_COLUMN] == 0:\n",
        "            t = [1, 0]\n",
        "        else:\n",
        "            t = [0, 1]\n",
        "        nsp_target = torch.Tensor(t)\n",
        "\n",
        "        # MLM target\n",
        "        mask_target = torch.Tensor(item[self.TARGET_COLUMN]).long()  \n",
        "        mask_target = mask_target.masked_fill_(token_mask, 0)\n",
        "        return inp, attention_mask, token_mask, mask_target, nsp_target\n",
        "\n",
        "    def prepare_dataset(self) -> pd.DataFrame:\n",
        "        sentences = []\n",
        "        nsp = []\n",
        "        sentence_lens = []\n",
        "\n",
        "        # Split sentences from dataset: \n",
        "        \n",
        "        for review in self.ds:\n",
        "            review_sentences = review.split(\".\")\n",
        "            sentences += review_sentences\n",
        "            self._update_length(review_sentences, sentence_lens)\n",
        "        self.optimal_sentence_length = self._find_optimal_sentence_length(sentence_lens)\n",
        "        \n",
        "        # Create vocabulary:\n",
        "\n",
        "        print(\"Create vocabulary\")  \n",
        "        for sentence in tqdm(sentences):  \n",
        "            s = self.tokenizer(sentence)  \n",
        "            self.counter.update(s)  \n",
        "        self._fill_vocab()\n",
        "\n",
        "        # Create training dataset:\n",
        "\n",
        "        print(\"Preprocessing dataset\")\n",
        "        for review in tqdm(self.ds):\n",
        "            review_sentences = review.split('.')\n",
        "            for i in range(len(review_sentences)-1):\n",
        "                # True NSP item\n",
        "                first, second = self.tokenizer(review_sentences[i]), self.tokenizer(review_sentences[i+1])\n",
        "                nsp.append(self._create_item(first, second, 1))\n",
        "\n",
        "                # False NSP item\n",
        "                first, second = self._select_false_nsp_sentences(sentences)\n",
        "                first, second = self.tokenizer(first), self.tokenizer(second)\n",
        "                nsp.append(self._create_item(first, second, 0))\n",
        "        df = pd.DataFrame(nsp, columns=self.columns)\n",
        "        return df\n",
        "\n",
        "    def _update_length(self, review_sentences, sentence_lens):\n",
        "        for word in review_sentences:\n",
        "            sentence_lens.append(len(word)) \n",
        "    \n",
        "    def _find_optimal_sentence_length(self, lengths: typing.List[int]):  \n",
        "        arr = np.array(lengths)  \n",
        "        return int(np.percentile(arr, self.OPTIMAL_LENGTH_PERCENTILE))\n",
        "    \n",
        "    def _fill_vocab(self):  \n",
        "        # specials= argument is only in 0.12.0 version  \n",
        "        # specials=[self.CLS, self.PAD, self.MASK, self.SEP, self.UNK]\n",
        "        self.vocab = vocab(self.counter, min_freq=2)  \n",
        "        # 0.11.0 uses this approach to insert specials  \n",
        "        self.vocab.insert_token(self.CLS, 0)  \n",
        "        self.vocab.insert_token(self.PAD, 1)  \n",
        "        self.vocab.insert_token(self.MASK, 2)  \n",
        "        self.vocab.insert_token(self.SEP, 3)  \n",
        "        self.vocab.insert_token(self.UNK, 4)  \n",
        "        self.vocab.set_default_index(4)\n",
        "\n",
        "    def _create_item(self, first: typing.List[str], second: typing.List[str], target: int = 1):  \n",
        "        # Create masked sentence item  \n",
        "        updated_first, first_mask = self._preprocess_sentence(first.copy())  \n",
        "        updated_second, second_mask = self._preprocess_sentence(second.copy())\n",
        "        nsp_sentence = updated_first + [self.SEP] + updated_second  \n",
        "        nsp_indices = self.vocab.lookup_indices(nsp_sentence)  \n",
        "        inverse_token_mask = first_mask + [True] + second_mask\n",
        "\n",
        "        # Create sentence item without masking random words  \n",
        "        first, _ = self._preprocess_sentence(first.copy(), should_mask=False)  \n",
        "        second, _ = self._preprocess_sentence(second.copy(), should_mask=False)  \n",
        "        original_nsp_sentence = first + [self.SEP] + second  \n",
        "        original_nsp_indices = self.vocab.lookup_indices(original_nsp_sentence)\n",
        "\n",
        "        if self.should_include_text:\n",
        "            return [nsp_sentence, nsp_indices, original_nsp_sentence, original_nsp_indices, inverse_token_mask, target]\n",
        "        else:\n",
        "            return [nsp_indices, original_nsp_indices, inverse_token_mask, target]\n",
        "\n",
        "    def _select_false_nsp_sentences(self, sentences):\n",
        "        return random.choice(sentences), random.choice(sentences)\n",
        "\n",
        "    def _preprocess_sentence(self, sentence, should_mask = True):\n",
        "        inverse_token_mask = [True for _ in range(max(len(sentence), self.optimal_sentence_length))]\n",
        "        if should_mask:\n",
        "            sentence, inverse_token_mask = self._mask_sentence(sentence)\n",
        "        return self._pad_sentence(sentence, inverse_token_mask)\n",
        "\n",
        "    # Step 1: Mask sentence\n",
        "\n",
        "    def _mask_sentence(self, sentence: typing.List[str]):  \n",
        "        len_s = len(sentence)  \n",
        "        inverse_token_mask = [True for _ in range(max(len_s, self.optimal_sentence_length))]  \n",
        "    \n",
        "        mask_amount = round(len_s * self.MASK_PERCENTAGE)  \n",
        "        for _ in range(mask_amount):  \n",
        "            i = random.randint(0, len_s - 1) \n",
        "            j = random.randint(5, len(self.vocab)-1) \n",
        "    \n",
        "            if random.random() < 0.8:  \n",
        "                sentence[i] = self.MASK  \n",
        "            else:\n",
        "                sentence[i] = self.vocab.lookup_token(j)  \n",
        "            inverse_token_mask[i] = False  \n",
        "        \n",
        "        return sentence, inverse_token_mask\n",
        "    \n",
        "    # Step 2:Preprocessing: [CLS] and [PAD] sentence\n",
        "\n",
        "    def _pad_sentence(self, sentence: typing.List[str], inverse_token_mask: typing.List[bool] = None):  \n",
        "        len_s = len(sentence)  \n",
        "    \n",
        "        if len_s >= self.optimal_sentence_length:  \n",
        "            s = sentence[:self.optimal_sentence_length]  \n",
        "        else:  \n",
        "            s = sentence + [self.PAD] * (self.optimal_sentence_length - len_s)  \n",
        "    \n",
        "        # inverse token mask should be padded as well  \n",
        "        if inverse_token_mask:  \n",
        "            len_m = len(inverse_token_mask)  \n",
        "            if len_m >= self.optimal_sentence_length:  \n",
        "                inverse_token_mask = inverse_token_mask[:self.optimal_sentence_length]  \n",
        "            else:  \n",
        "                inverse_token_mask = inverse_token_mask + [True] * (self.optimal_sentence_length - len_m)  \n",
        "        return s, inverse_token_mask"
      ],
      "metadata": {
        "id": "nFA_rkrWGhhL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "mydataset = IMDBBertDataset('/content/drive/MyDrive/BERT with Pytorch from Scratch/data/IMDB Dataset.csv', ds_from=0, ds_to=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QifRl_omNM7i",
        "outputId": "ab73d96e-2e8a-4c58-fa1f-2b468ac35f40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create vocabulary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7123/7123 [00:00<00:00, 61517.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:01<00:00, 294.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.92 s, sys: 160 ms, total: 3.08 s\n",
            "Wall time: 3.11 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydataset.df"
      ],
      "metadata": {
        "id": "4gRA13xFnVO8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "79a9a1a7-44af-47d2-c368-364242051077"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          masked_indices  \\\n",
              "0      [5, 6, 7, 8, 9, 2, 11, 2, 13, 14, 15, 16, 17, ...   \n",
              "1      [2, 20, 211, 2, 48, 7, 320, 194, 56, 589, 27, ...   \n",
              "2      [24, 25, 26, 27, 2, 29, 30, 1978, 32, 33, 34, ...   \n",
              "3      [1306, 2186, 199, 2, 54, 1002, 2236, 142, 2, 4...   \n",
              "4      [7, 36, 37, 12, 2, 35, 39, 2, 40, 41, 4, 2, 43...   \n",
              "...                                                  ...   \n",
              "13241  [29, 320, 465, 7, 4, 3914, 2642, 6, 7, 3898, 1...   \n",
              "13242  [32, 101, 2, 310, 63, 109, 39, 4031, 3090, 20,...   \n",
              "13243  [692, 2, 339, 20, 328, 2369, 24, 20, 2, 86, 22...   \n",
              "13244  [527, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
              "13245  [2, 54, 2758, 242, 4609, 30, 6066, 831, 532, 2...   \n",
              "\n",
              "                                                 indices  \\\n",
              "0      [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...   \n",
              "1      [292, 20, 211, 1949, 48, 7, 320, 194, 56, 589,...   \n",
              "2      [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...   \n",
              "3      [1306, 2186, 199, 402, 54, 1002, 2236, 142, 46...   \n",
              "4      [7, 36, 37, 12, 38, 35, 39, 17, 40, 41, 4, 42,...   \n",
              "...                                                  ...   \n",
              "13241  [29, 320, 465, 7, 4, 3914, 2642, 6, 7, 3898, 1...   \n",
              "13242  [32, 101, 30, 310, 63, 109, 39, 54, 3090, 20, ...   \n",
              "13243  [692, 170, 339, 20, 328, 2369, 24, 20, 21, 86,...   \n",
              "13244  [527, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...   \n",
              "13245  [48, 54, 2758, 242, 69, 30, 718, 831, 532, 27,...   \n",
              "\n",
              "                                              token_mask  is_next  \n",
              "0      [True, True, True, True, True, False, True, Fa...        1  \n",
              "1      [False, True, True, False, True, True, True, T...        0  \n",
              "2      [True, True, True, True, False, True, True, Fa...        1  \n",
              "3      [True, True, True, False, True, True, True, Tr...        0  \n",
              "4      [True, True, True, True, False, True, True, Fa...        1  \n",
              "...                                                  ...      ...  \n",
              "13241  [True, True, True, True, True, True, True, Tru...        0  \n",
              "13242  [True, True, False, True, True, True, True, Fa...        1  \n",
              "13243  [True, False, True, True, True, True, True, Tr...        0  \n",
              "13244  [True, True, True, True, True, True, True, Tru...        1  \n",
              "13245  [False, True, True, True, False, True, False, ...        0  \n",
              "\n",
              "[13246 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e684ea32-1f0e-47bf-b20e-b63326b8a4f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>masked_indices</th>\n",
              "      <th>indices</th>\n",
              "      <th>token_mask</th>\n",
              "      <th>is_next</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[5, 6, 7, 8, 9, 2, 11, 2, 13, 14, 15, 16, 17, ...</td>\n",
              "      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...</td>\n",
              "      <td>[True, True, True, True, True, False, True, Fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 20, 211, 2, 48, 7, 320, 194, 56, 589, 27, ...</td>\n",
              "      <td>[292, 20, 211, 1949, 48, 7, 320, 194, 56, 589,...</td>\n",
              "      <td>[False, True, True, False, True, True, True, T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[24, 25, 26, 27, 2, 29, 30, 1978, 32, 33, 34, ...</td>\n",
              "      <td>[24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 3...</td>\n",
              "      <td>[True, True, True, True, False, True, True, Fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1306, 2186, 199, 2, 54, 1002, 2236, 142, 2, 4...</td>\n",
              "      <td>[1306, 2186, 199, 402, 54, 1002, 2236, 142, 46...</td>\n",
              "      <td>[True, True, True, False, True, True, True, Tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[7, 36, 37, 12, 2, 35, 39, 2, 40, 41, 4, 2, 43...</td>\n",
              "      <td>[7, 36, 37, 12, 38, 35, 39, 17, 40, 41, 4, 42,...</td>\n",
              "      <td>[True, True, True, True, False, True, True, Fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13241</th>\n",
              "      <td>[29, 320, 465, 7, 4, 3914, 2642, 6, 7, 3898, 1...</td>\n",
              "      <td>[29, 320, 465, 7, 4, 3914, 2642, 6, 7, 3898, 1...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13242</th>\n",
              "      <td>[32, 101, 2, 310, 63, 109, 39, 4031, 3090, 20,...</td>\n",
              "      <td>[32, 101, 30, 310, 63, 109, 39, 54, 3090, 20, ...</td>\n",
              "      <td>[True, True, False, True, True, True, True, Fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13243</th>\n",
              "      <td>[692, 2, 339, 20, 328, 2369, 24, 20, 2, 86, 22...</td>\n",
              "      <td>[692, 170, 339, 20, 328, 2369, 24, 20, 21, 86,...</td>\n",
              "      <td>[True, False, True, True, True, True, True, Tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13244</th>\n",
              "      <td>[527, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[527, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13245</th>\n",
              "      <td>[2, 54, 2758, 242, 4609, 30, 6066, 831, 532, 2...</td>\n",
              "      <td>[48, 54, 2758, 242, 69, 30, 718, 831, 532, 27,...</td>\n",
              "      <td>[False, True, True, True, False, True, False, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13246 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e684ea32-1f0e-47bf-b20e-b63326b8a4f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e684ea32-1f0e-47bf-b20e-b63326b8a4f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e684ea32-1f0e-47bf-b20e-b63326b8a4f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create sample input tensor"
      ],
      "metadata": {
        "id": "fOwMops4BMYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "mydataloader = DataLoader(mydataset, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "8K8XQ45rAYgG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item = next(iter(mydataloader))\n",
        "print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8vUgHne_nBD",
        "outputId": "344d90b3-743d-4833-9610-ebba23ac1de1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   2, 5074,   30,  ...,    1,    1,    1],\n",
            "        [  86,    2,    2,  ...,    1,    1,    1],\n",
            "        [ 722,   27, 1105,  ...,    1,    1,    1],\n",
            "        [   2,  240,   27,  ...,    1,    1,    1],\n",
            "        [  29,  320,   30,  ...,    1,    1,    1]]), tensor([[[False, False, False,  ...,  True,  True,  True]],\n",
            "\n",
            "        [[False, False, False,  ...,  True,  True,  True]],\n",
            "\n",
            "        [[False, False, False,  ...,  True,  True,  True]],\n",
            "\n",
            "        [[False, False, False,  ...,  True,  True,  True]],\n",
            "\n",
            "        [[False, False, False,  ...,  True,  True,  True]]]), tensor([[False,  True,  True,  ...,  True,  True,  True],\n",
            "        [ True, False, False,  ...,  True,  True,  True],\n",
            "        [ True,  True,  True,  ...,  True,  True,  True],\n",
            "        [False,  True,  True,  ...,  True,  True,  True],\n",
            "        [ True,  True,  True,  ...,  True,  True,  True]]), tensor([[5346,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,   19,  202,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0],\n",
            "        [5607,    0,    0,  ...,    0,    0,    0],\n",
            "        [   0,    0,    0,  ...,    0,    0,    0]]), tensor([[0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.],\n",
            "        [1., 0.],\n",
            "        [0., 1.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input, batch_attention_mask, inverse_token_mask, token_target, nsp_target = item\n",
        "batch_input = batch_input.to(device)\n",
        "batch_attention_mask = batch_attention_mask.to(device)\n",
        "inverse_token_mask = inverse_token_mask.to(device)\n",
        "token_target = token_target.to(device)\n",
        "nsp_target = nsp_target.to(device)"
      ],
      "metadata": {
        "id": "PaIkUoVlmBWD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build pyTorch model"
      ],
      "metadata": {
        "id": "wPYqsrq_Rt_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Joint Embedding\n",
        "###### - Token embedding: is used to encode word tokens. \n",
        "###### - Segment embedding: encodes belonging to the first or to the second sentence. We preprocess input sequence the next way: if the token belongs to the first sentence, set 0, otherwise set 1.\n",
        "###### - Position embedding: encodes the position of the word in the sentence (using periodic functions to encode positions)"
      ],
      "metadata": {
        "id": "nFsZtTgBS7iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JointEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, size):\n",
        "        super(JointEmbedding, self).__init__()\n",
        "\n",
        "        self.size = size\n",
        "\n",
        "        self.token_emb = nn.Embedding(vocab_size, size)\n",
        "        self.segment_emb = nn.Embedding(2, size)\n",
        "\n",
        "        self.norm = nn.LayerNorm(size)\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        sentence_size = input_tensor.size(-1)\n",
        "        pos_tensor = self.attention_position(self.size, input_tensor)\n",
        "\n",
        "        segment_tensor = torch.zeros_like(input_tensor).to(input_tensor.device)\n",
        "        segment_tensor[:, sentence_size // 2 + 1:] = 1\n",
        "\n",
        "        output = self.token_emb(input_tensor) + self.segment_emb(segment_tensor) + pos_tensor\n",
        "        return self.norm(output)\n",
        "\n",
        "    def attention_position(self, dim, input_tensor):\n",
        "        batch_size = input_tensor.size(0)\n",
        "        sentence_size = input_tensor.size(-1)\n",
        "\n",
        "        pos = torch.arange(sentence_size, dtype=torch.long).to(input_tensor.device)\n",
        "        d = torch.arange(dim, dtype=torch.long).to(input_tensor.device)\n",
        "        d = (2 * d / dim)\n",
        "\n",
        "        pos = pos.unsqueeze(1)\n",
        "        pos = pos / (1e4 ** d)\n",
        "\n",
        "        pos[:, ::2] = torch.sin(pos[:, ::2])\n",
        "        pos[:, 1::2] = torch.cos(pos[:, 1::2])\n",
        "\n",
        "        return pos.expand(batch_size, *pos.size())\n",
        "\n",
        "    def numeric_position(self, dim, input_tensor):\n",
        "        pos_tensor = torch.arange(dim, dtype=torch.long).to(input_tensor.device)\n",
        "        return pos_tensor.expand_as(input_tensor)"
      ],
      "metadata": {
        "id": "3c7qEllkSe35"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jointemb = JointEmbedding(len(mydataset.vocab), 128)\n",
        "jointemb.to(device)"
      ],
      "metadata": {
        "id": "fle89F-PCFYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495ac03f-8840-4f47-e691-c59870235763"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "JointEmbedding(\n",
              "  (token_emb): Embedding(6314, 128)\n",
              "  (segment_emb): Embedding(2, 128)\n",
              "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = batch_input"
      ],
      "metadata": {
        "id": "BLJ3pfYVGLmN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = jointemb(input_tensor)"
      ],
      "metadata": {
        "id": "qwyM7M_rPAQa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHG1pNFIMTzY",
        "outputId": "487b92c9-856f-433b-ade2-e637f382ac63"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 241, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Attention Head\n",
        "######(the heart of Transformer)"
      ],
      "metadata": {
        "id": "FUgB_o9WyzuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):  \n",
        "  \n",
        "    def __init__(self, dim_inp, dim_out):  \n",
        "        super(AttentionHead, self).__init__()  \n",
        "  \n",
        "        self.dim_inp = dim_inp  \n",
        "  \n",
        "        self.q = nn.Linear(dim_inp, dim_out)  \n",
        "        self.k = nn.Linear(dim_inp, dim_out)  \n",
        "        self.v = nn.Linear(dim_inp, dim_out)  \n",
        "  \n",
        "    def forward(self, input_tensor: torch.Tensor, attention_mask: torch.Tensor = None):  \n",
        "        query, key, value = self.q(input_tensor), self.k(input_tensor), self.v(input_tensor)  \n",
        "  \n",
        "        scale = query.size(1) ** 0.5  \n",
        "        scores = torch.bmm(query, key.transpose(1, 2)) / scale  \n",
        "  \n",
        "        scores = scores.masked_fill_(attention_mask, -1e9)  \n",
        "        attn = f.softmax(scores, dim=-1)  \n",
        "        context = torch.bmm(attn, value)  \n",
        "  \n",
        "        return context"
      ],
      "metadata": {
        "id": "17vJ0YTYU4HJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myAttentionHead = AttentionHead(128,512)\n",
        "myAttentionHead.to(device)"
      ],
      "metadata": {
        "id": "f_9EEmQW64Rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a214918d-56b3-4777-c018-a72c7d592cab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionHead(\n",
              "  (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "  (v): Linear(in_features=128, out_features=512, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query, key, value = myAttentionHead.q(x), myAttentionHead.k(x), myAttentionHead.v(x)  \n",
        "\n",
        "scale = query.size(1) ** 0.5  \n",
        "scores = torch.bmm(query, key.transpose(1, 2)) / scale  \n",
        "\n",
        "scores = scores.masked_fill_(batch_attention_mask, -1e9)  \n",
        "attn = f.softmax(scores, dim=-1)  \n",
        "context = torch.bmm(attn, value) \n",
        " "
      ],
      "metadata": {
        "id": "otYh7h4Q_wZg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = torch.bmm(query, key.transpose(1, 2)) / scale\n",
        "scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xob5KKHQHVLV",
        "outputId": "5ca5526b-e5f1-43d9-cd6f-9aaf94364026"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 241, 241])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = scores.masked_fill_(batch_attention_mask, -1e9)\n",
        "scores[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ho52ih8MVO7",
        "outputId": "9de39e8b-3b29-4157-f68a-aeb3556bf47c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.4754e-01, -1.5687e-01,  2.4132e-01,  ..., -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 1.9747e-01, -4.8152e-02, -5.7293e-02,  ..., -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 2.6474e-01,  3.3935e-01,  4.9777e-01,  ..., -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        ...,\n",
              "        [ 7.2873e-01, -9.4207e-02,  7.5281e-01,  ..., -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 6.6566e-01, -9.5213e-02,  7.1552e-01,  ..., -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09],\n",
              "        [ 6.1017e-01, -1.3832e-01,  6.8698e-01,  ..., -1.0000e+09,\n",
              "         -1.0000e+09, -1.0000e+09]], device='cuda:0',\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn = f.softmax(scores, dim=-1) \n",
        "attn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhI01BkCPkgZ",
        "outputId": "a807d64f-0ed3-4ac2-d168-402298b399e4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 241, 241])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MultiHead Attention\n",
        "\n",
        "######Single attention layer (head) is restricted to learn only the information from one particular subspace. Multi-head attention is the set of parallel attention heads that learns to retrieve the information from different representations. You may look on them as on filters in Convolutional Neural Networks."
      ],
      "metadata": {
        "id": "KaON_XioRtGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):  \n",
        "  \n",
        "    def __init__(self, num_heads, dim_inp, dim_out):  \n",
        "        super(MultiHeadAttention, self).__init__()  \n",
        "  \n",
        "        self.heads = nn.ModuleList([  \n",
        "            AttentionHead(dim_inp, dim_out) for _ in range(num_heads)  \n",
        "        ])  \n",
        "        self.linear = nn.Linear(dim_out * num_heads, dim_inp)  \n",
        "        self.norm = nn.LayerNorm(dim_inp)  \n",
        "  \n",
        "    def forward(self, input_tensor: torch.Tensor, attention_mask: torch.Tensor):  \n",
        "        s = [head(input_tensor, attention_mask) for head in self.heads]  \n",
        "        scores = torch.cat(s, dim=-1)  \n",
        "        scores = self.linear(scores)  \n",
        "        return self.norm(scores)"
      ],
      "metadata": {
        "id": "8T6pu-LgU4T0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myMutiHeadAttention = MultiHeadAttention(2, 128, 512)\n",
        "myMutiHeadAttention.to(device)"
      ],
      "metadata": {
        "id": "8bOHy1getgnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfac65a-e34b-42d5-db10-8381d0ae7a37"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiHeadAttention(\n",
              "  (heads): ModuleList(\n",
              "    (0): AttentionHead(\n",
              "      (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "      (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=512, bias=True)\n",
              "    )\n",
              "    (1): AttentionHead(\n",
              "      (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "      (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=1024, out_features=128, bias=True)\n",
              "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = [head(x, batch_attention_mask) for head in myMutiHeadAttention.heads]\n",
        "scores = torch.cat(s, dim=-1)\n",
        "scores.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYWcpt8Dt5hi",
        "outputId": "677978a5-e4f2-45f9-dc6d-3875f8477242"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 241, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Encoder\n",
        "###### (For simplicity, we use only one layer)\n"
      ],
      "metadata": {
        "id": "SBF-uyaazzk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):  \n",
        "  \n",
        "    def __init__(self, dim_inp, dim_out, attention_heads=2, dropout=0.1):  \n",
        "        super(Encoder, self).__init__()  \n",
        "  \n",
        "        self.attention = MultiHeadAttention(attention_heads, dim_inp, dim_out) \n",
        "        self.feed_forward = nn.Sequential(  \n",
        "            nn.Linear(dim_inp, dim_out),  \n",
        "            nn.Dropout(dropout),  \n",
        "            nn.GELU(),  \n",
        "            nn.Linear(dim_out, dim_inp),  \n",
        "            nn.Dropout(dropout)  \n",
        "        )\n",
        "        self.norm = nn.LayerNorm(dim_inp)  \n",
        "  \n",
        "    def forward(self, input_tensor: torch.Tensor, attention_mask: torch.Tensor):  \n",
        "        context = self.attention(input_tensor, attention_mask)  \n",
        "        res = self.feed_forward(context)  \n",
        "        return self.norm(res)"
      ],
      "metadata": {
        "id": "mb5oClgszqRe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myEncoder = Encoder(128, 512)\n",
        "myEncoder.to(device)"
      ],
      "metadata": {
        "id": "mwLZ6X-61jLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c72dd8-6253-42dd-983e-a8c98d8645b9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (attention): MultiHeadAttention(\n",
              "    (heads): ModuleList(\n",
              "      (0): AttentionHead(\n",
              "        (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (v): Linear(in_features=128, out_features=512, bias=True)\n",
              "      )\n",
              "      (1): AttentionHead(\n",
              "        (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "        (v): Linear(in_features=128, out_features=512, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (linear): Linear(in_features=1024, out_features=128, bias=True)\n",
              "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (feed_forward): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "    (1): Dropout(p=0.1, inplace=False)\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (4): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myEncoder(x, batch_attention_mask).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAzb6Fj91wBv",
        "outputId": "d03d133b-48cf-494c-82a7-e2ed4993c38a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 241, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BERT\n",
        "######BERT module is a container that combines all the modules together and returns the output."
      ],
      "metadata": {
        "id": "oKHGcO-x1Se7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT(nn.Module):  \n",
        "  \n",
        "    def __init__(self, vocab_size, dim_inp, dim_out, attention_heads):  \n",
        "        super(BERT, self).__init__()  \n",
        "  \n",
        "        self.embedding = JointEmbedding(vocab_size, dim_inp)  \n",
        "        self.encoder = Encoder(dim_inp, dim_out, attention_heads)  \n",
        "  \n",
        "        self.token_prediction_layer = nn.Linear(dim_inp, vocab_size)  \n",
        "        self.softmax = nn.LogSoftmax(dim=-1)  \n",
        "        self.classification_layer = nn.Linear(dim_inp, 2)  \n",
        "  \n",
        "    def forward(self, input_tensor: torch.Tensor, attention_mask: torch.Tensor):  \n",
        "        embedded = self.embedding(input_tensor)  \n",
        "        encoded = self.encoder(embedded, attention_mask)  \n",
        "  \n",
        "        token_predictions = self.token_prediction_layer(encoded)  \n",
        "  \n",
        "        first_word = encoded[:, 0, :]  \n",
        "        return self.softmax(token_predictions), self.classification_layer(first_word)"
      ],
      "metadata": {
        "id": "Fr53aw7R1NjJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myBERT = BERT(len(mydataset.vocab), 128, 512, 2)\n",
        "myBERT.to(device)"
      ],
      "metadata": {
        "id": "AmnPVrGc2EUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c03a54c-fdbc-440d-ce9d-b6ede959a17f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT(\n",
              "  (embedding): JointEmbedding(\n",
              "    (token_emb): Embedding(6314, 128)\n",
              "    (segment_emb): Embedding(2, 128)\n",
              "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (encoder): Encoder(\n",
              "    (attention): MultiHeadAttention(\n",
              "      (heads): ModuleList(\n",
              "        (0): AttentionHead(\n",
              "          (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (v): Linear(in_features=128, out_features=512, bias=True)\n",
              "        )\n",
              "        (1): AttentionHead(\n",
              "          (q): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (k): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (v): Linear(in_features=128, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (linear): Linear(in_features=1024, out_features=128, bias=True)\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (feed_forward): Sequential(\n",
              "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "      (1): Dropout(p=0.1, inplace=False)\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "      (4): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (token_prediction_layer): Linear(in_features=128, out_features=6314, bias=True)\n",
              "  (softmax): LogSoftmax(dim=-1)\n",
              "  (classification_layer): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_predictions, first_word = myBERT(input_tensor, batch_attention_mask)"
      ],
      "metadata": {
        "id": "S6kHhdG53oEH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tMp5fLo4S8E",
        "outputId": "0940c1e2-4166-42d2-866b-430fbc40c483"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 241, 6314])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_word.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_RlojeV4qD8",
        "outputId": "30ec0baf-674c-4dff-99e5-a7e0c57aed33"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train the model\n"
      ],
      "metadata": {
        "id": "5rz1q4bwC3B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time\n",
        "from pathlib import Path\n",
        "import os"
      ],
      "metadata": {
        "id": "xxXn3Aa6qaA7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertTrainer:\n",
        "\n",
        "    def __init__(self,\n",
        "                 model: BERT,\n",
        "                 dataset: IMDBBertDataset,\n",
        "                 log_dir: Path,\n",
        "                 checkpoint_dir: Path = None,\n",
        "                 print_progress_every: int = 50,\n",
        "                 batch_size: int = 24,\n",
        "                 learning_rate: float = 0.005,\n",
        "                 epochs: int = 5,\n",
        "                 device: str = 'cpu',\n",
        "                 ):\n",
        "        self.model = model\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.current_epoch = 0\n",
        "\n",
        "        self.loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        self.writer = SummaryWriter(str(log_dir))\n",
        "        self.checkpoint_dir = Path(checkpoint_dir)\n",
        "        self._print_every = print_progress_every\n",
        "\n",
        "        self.criterion = nn.BCEWithLogitsLoss().to(self.device)\n",
        "        self.ml_criterion = nn.NLLLoss(ignore_index=0).to(self.device)\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.015)\n",
        "\n",
        "    def train(self, epoch: int):\n",
        "        print(f\"Begin epoch {epoch}\")\n",
        "\n",
        "        prev = time.time()\n",
        "        average_nsp_loss = 0\n",
        "        average_mlm_loss = 0\n",
        "        for i, value in enumerate(self.loader):\n",
        "            index = i + 1\n",
        "            inp, mask, inverse_token_mask, token_target, nsp_target = value\n",
        "            inp = inp.to(self.device)\n",
        "            mask = mask.to(self.device)\n",
        "            inverse_token_mask = inverse_token_mask.to(self.device)\n",
        "            token_target = token_target.to(self.device)\n",
        "            nsp_target = nsp_target.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            token, nsp = self.model(inp, mask)\n",
        "\n",
        "            tm = inverse_token_mask.unsqueeze(-1).expand_as(token)\n",
        "            token = token.masked_fill(tm, 0)\n",
        "\n",
        "            loss_token = self.ml_criterion(token.transpose(1, 2), token_target)\n",
        "            loss_nsp = self.criterion(nsp, nsp_target)\n",
        "\n",
        "            loss = loss_token + loss_nsp\n",
        "            average_nsp_loss += loss_nsp\n",
        "            average_mlm_loss += loss_token\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if index % self._print_every == 0:\n",
        "                elapsed = time.gmtime(time.time() - prev)\n",
        "\n",
        "                log_nsp_loss = average_nsp_loss / self._print_every\n",
        "                log_mlm_loss = average_mlm_loss / self._print_every\n",
        "                log_nsp_acc = 100*(nsp.argmax(1) == nsp_target.argmax(1)).sum() / nsp.size(0)\n",
        "                log_mlm_acc = 100*(token.argmax(-1).masked_select(~inverse_token_mask) == token_target.masked_select(~inverse_token_mask)).sum() / (token.size(0) * token.size(1))\n",
        "\n",
        "                print(f\"{time.strftime('%H:%M:%S', elapsed)} | Epoch {epoch} | Step {index}/{len(self.loader)} | \"\n",
        "                      f\"NSP Loss: {log_nsp_loss:.2f} | MLM Loss: {log_mlm_loss:.2f} | NSP Accuracy: {log_nsp_acc:.2f}% | MLM Accuracy: {log_mlm_acc:.2f}%\")\n",
        "\n",
        "                global_step = index + epoch*len(self.loader)\n",
        "                self.writer.add_scalar(\"NSP loss\", log_nsp_loss, global_step=global_step)\n",
        "                self.writer.add_scalar(\"MLM loss\", log_mlm_loss, global_step=global_step)\n",
        "                self.writer.add_scalar(\"NSP accuracy\", log_nsp_acc, global_step=global_step)\n",
        "                self.writer.add_scalar(\"Token accuracy\", log_mlm_acc, global_step=global_step)\n",
        "\n",
        "                average_nsp_loss = 0\n",
        "                average_mlm_loss = 0\n",
        "        return loss\n",
        "\n",
        "    def __call__(self):\n",
        "        if self.checkpoint_dir and os.path.exists(self.checkpoint_dir.joinpath(\"checkpoint_last.txt\")):\n",
        "            with open(self.checkpoint_dir.joinpath(\"checkpoint_last.txt\")) as f:\n",
        "                name = f.readline().strip()\n",
        "            self.load_checkpoint(self.checkpoint_dir.joinpath(name))\n",
        "            start_epoch = self.current_epoch + 1\n",
        "        else:\n",
        "            start_epoch = 0\n",
        "\n",
        "        for self.current_epoch in range(start_epoch, self.epochs):\n",
        "            loss = self.train(self.current_epoch)\n",
        "            self.save_checkpoint(epoch=self.current_epoch, loss=loss)\n",
        "\n",
        "    def save_checkpoint(self, epoch, loss):\n",
        "        if not self.checkpoint_dir:\n",
        "            return\n",
        "\n",
        "        prev = time.time()\n",
        "        name = f\"checkpoint_epoch{epoch}.pt\"\n",
        "        print(f\"Saving model checkpoint epoch {epoch} to {self.checkpoint_dir.joinpath(name)}\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "        }, self.checkpoint_dir.joinpath(name))\n",
        "\n",
        "        with open(self.checkpoint_dir.joinpath(\"checkpoint_last.txt\"), \"w\") as f:\n",
        "            f.write(name)\n",
        "\n",
        "    def load_checkpoint(self, path: Path):\n",
        "        print(f\"Loading model checkpoint from {path}\")\n",
        "        checkpoint = torch.load(path)\n",
        "        self.current_epoch = checkpoint['epoch']\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        print(f\"Model loaded at epoch {self.current_epoch}.\")"
      ],
      "metadata": {
        "id": "lCBURxe1C6hy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytrainer = BertTrainer(myBERT, mydataset, log_dir='./checkpoints/logs', checkpoint_dir='./checkpoints',\n",
        "                        epochs=5, device=device)"
      ],
      "metadata": {
        "id": "bDN83jwnU9_v"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mytrainer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc4GEcsMVQSG",
        "outputId": "01476275-7d82-45ca-ca3f-7594ef83982e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin epoch 0\n",
            "00:00:02 | Epoch 0 | Step 50/552 | NSP Loss: 0.70 | MLM Loss: 6.40 | NSP Accuracy: 41.67% | MLM Accuracy: 0.05%\n",
            "00:00:04 | Epoch 0 | Step 100/552 | NSP Loss: 0.70 | MLM Loss: 6.40 | NSP Accuracy: 41.67% | MLM Accuracy: 0.07%\n",
            "00:00:06 | Epoch 0 | Step 150/552 | NSP Loss: 0.69 | MLM Loss: 6.39 | NSP Accuracy: 45.83% | MLM Accuracy: 0.12%\n",
            "00:00:08 | Epoch 0 | Step 200/552 | NSP Loss: 0.70 | MLM Loss: 6.34 | NSP Accuracy: 25.00% | MLM Accuracy: 0.10%\n",
            "00:00:10 | Epoch 0 | Step 250/552 | NSP Loss: 0.70 | MLM Loss: 6.40 | NSP Accuracy: 37.50% | MLM Accuracy: 0.19%\n",
            "00:00:12 | Epoch 0 | Step 300/552 | NSP Loss: 0.70 | MLM Loss: 6.36 | NSP Accuracy: 50.00% | MLM Accuracy: 0.10%\n",
            "00:00:14 | Epoch 0 | Step 350/552 | NSP Loss: 0.69 | MLM Loss: 6.35 | NSP Accuracy: 54.17% | MLM Accuracy: 0.28%\n",
            "00:00:16 | Epoch 0 | Step 400/552 | NSP Loss: 0.70 | MLM Loss: 6.41 | NSP Accuracy: 54.17% | MLM Accuracy: 0.07%\n",
            "00:00:18 | Epoch 0 | Step 450/552 | NSP Loss: 0.70 | MLM Loss: 6.38 | NSP Accuracy: 33.33% | MLM Accuracy: 0.03%\n",
            "00:00:20 | Epoch 0 | Step 500/552 | NSP Loss: 0.70 | MLM Loss: 6.37 | NSP Accuracy: 45.83% | MLM Accuracy: 0.12%\n",
            "00:00:22 | Epoch 0 | Step 550/552 | NSP Loss: 0.69 | MLM Loss: 6.38 | NSP Accuracy: 41.67% | MLM Accuracy: 0.07%\n",
            "Saving model checkpoint epoch 0 to checkpoints/checkpoint_epoch0.pt\n",
            "Begin epoch 1\n",
            "00:00:02 | Epoch 1 | Step 50/552 | NSP Loss: 0.70 | MLM Loss: 6.35 | NSP Accuracy: 54.17% | MLM Accuracy: 0.10%\n",
            "00:00:04 | Epoch 1 | Step 100/552 | NSP Loss: 0.70 | MLM Loss: 6.35 | NSP Accuracy: 37.50% | MLM Accuracy: 0.05%\n",
            "00:00:06 | Epoch 1 | Step 150/552 | NSP Loss: 0.70 | MLM Loss: 6.34 | NSP Accuracy: 41.67% | MLM Accuracy: 0.21%\n",
            "00:00:08 | Epoch 1 | Step 200/552 | NSP Loss: 0.70 | MLM Loss: 6.33 | NSP Accuracy: 45.83% | MLM Accuracy: 0.19%\n",
            "00:00:10 | Epoch 1 | Step 250/552 | NSP Loss: 0.70 | MLM Loss: 6.39 | NSP Accuracy: 54.17% | MLM Accuracy: 0.05%\n",
            "00:00:12 | Epoch 1 | Step 300/552 | NSP Loss: 0.70 | MLM Loss: 6.45 | NSP Accuracy: 37.50% | MLM Accuracy: 0.07%\n",
            "00:00:14 | Epoch 1 | Step 350/552 | NSP Loss: 0.70 | MLM Loss: 6.39 | NSP Accuracy: 45.83% | MLM Accuracy: 0.19%\n",
            "00:00:16 | Epoch 1 | Step 400/552 | NSP Loss: 0.70 | MLM Loss: 6.32 | NSP Accuracy: 54.17% | MLM Accuracy: 0.09%\n",
            "00:00:18 | Epoch 1 | Step 450/552 | NSP Loss: 0.69 | MLM Loss: 6.38 | NSP Accuracy: 70.83% | MLM Accuracy: 0.03%\n",
            "00:00:20 | Epoch 1 | Step 500/552 | NSP Loss: 0.69 | MLM Loss: 6.38 | NSP Accuracy: 62.50% | MLM Accuracy: 0.21%\n",
            "00:00:22 | Epoch 1 | Step 550/552 | NSP Loss: 0.70 | MLM Loss: 6.38 | NSP Accuracy: 66.67% | MLM Accuracy: 0.14%\n",
            "Saving model checkpoint epoch 1 to checkpoints/checkpoint_epoch1.pt\n",
            "Begin epoch 2\n",
            "00:00:02 | Epoch 2 | Step 50/552 | NSP Loss: 0.70 | MLM Loss: 6.29 | NSP Accuracy: 62.50% | MLM Accuracy: 0.09%\n",
            "00:00:04 | Epoch 2 | Step 100/552 | NSP Loss: 0.69 | MLM Loss: 6.34 | NSP Accuracy: 41.67% | MLM Accuracy: 0.09%\n",
            "00:00:06 | Epoch 2 | Step 150/552 | NSP Loss: 0.70 | MLM Loss: 6.38 | NSP Accuracy: 58.33% | MLM Accuracy: 0.12%\n",
            "00:00:08 | Epoch 2 | Step 200/552 | NSP Loss: 0.70 | MLM Loss: 6.37 | NSP Accuracy: 45.83% | MLM Accuracy: 0.10%\n",
            "00:00:10 | Epoch 2 | Step 250/552 | NSP Loss: 0.69 | MLM Loss: 6.40 | NSP Accuracy: 66.67% | MLM Accuracy: 0.12%\n",
            "00:00:12 | Epoch 2 | Step 300/552 | NSP Loss: 0.69 | MLM Loss: 6.39 | NSP Accuracy: 50.00% | MLM Accuracy: 0.10%\n",
            "00:00:14 | Epoch 2 | Step 350/552 | NSP Loss: 0.70 | MLM Loss: 6.43 | NSP Accuracy: 62.50% | MLM Accuracy: 0.19%\n",
            "00:00:16 | Epoch 2 | Step 400/552 | NSP Loss: 0.69 | MLM Loss: 6.36 | NSP Accuracy: 62.50% | MLM Accuracy: 0.02%\n",
            "00:00:18 | Epoch 2 | Step 450/552 | NSP Loss: 0.70 | MLM Loss: 6.41 | NSP Accuracy: 66.67% | MLM Accuracy: 0.16%\n",
            "00:00:20 | Epoch 2 | Step 500/552 | NSP Loss: 0.69 | MLM Loss: 6.28 | NSP Accuracy: 41.67% | MLM Accuracy: 0.10%\n",
            "00:00:22 | Epoch 2 | Step 550/552 | NSP Loss: 0.70 | MLM Loss: 6.34 | NSP Accuracy: 45.83% | MLM Accuracy: 0.12%\n",
            "Saving model checkpoint epoch 2 to checkpoints/checkpoint_epoch2.pt\n",
            "Begin epoch 3\n",
            "00:00:02 | Epoch 3 | Step 50/552 | NSP Loss: 0.69 | MLM Loss: 6.31 | NSP Accuracy: 50.00% | MLM Accuracy: 0.09%\n",
            "00:00:04 | Epoch 3 | Step 100/552 | NSP Loss: 0.70 | MLM Loss: 6.35 | NSP Accuracy: 41.67% | MLM Accuracy: 0.07%\n",
            "00:00:06 | Epoch 3 | Step 150/552 | NSP Loss: 0.69 | MLM Loss: 6.32 | NSP Accuracy: 54.17% | MLM Accuracy: 0.10%\n",
            "00:00:08 | Epoch 3 | Step 200/552 | NSP Loss: 0.70 | MLM Loss: 6.36 | NSP Accuracy: 50.00% | MLM Accuracy: 0.09%\n",
            "00:00:10 | Epoch 3 | Step 250/552 | NSP Loss: 0.70 | MLM Loss: 6.38 | NSP Accuracy: 29.17% | MLM Accuracy: 0.12%\n",
            "00:00:12 | Epoch 3 | Step 300/552 | NSP Loss: 0.69 | MLM Loss: 6.38 | NSP Accuracy: 58.33% | MLM Accuracy: 0.05%\n",
            "00:00:14 | Epoch 3 | Step 350/552 | NSP Loss: 0.70 | MLM Loss: 6.34 | NSP Accuracy: 54.17% | MLM Accuracy: 0.09%\n",
            "00:00:16 | Epoch 3 | Step 400/552 | NSP Loss: 0.70 | MLM Loss: 6.40 | NSP Accuracy: 50.00% | MLM Accuracy: 0.12%\n",
            "00:00:18 | Epoch 3 | Step 450/552 | NSP Loss: 0.69 | MLM Loss: 6.37 | NSP Accuracy: 41.67% | MLM Accuracy: 0.10%\n",
            "00:00:20 | Epoch 3 | Step 500/552 | NSP Loss: 0.69 | MLM Loss: 6.39 | NSP Accuracy: 54.17% | MLM Accuracy: 0.14%\n",
            "00:00:22 | Epoch 3 | Step 550/552 | NSP Loss: 0.70 | MLM Loss: 6.39 | NSP Accuracy: 54.17% | MLM Accuracy: 0.17%\n",
            "Saving model checkpoint epoch 3 to checkpoints/checkpoint_epoch3.pt\n",
            "Begin epoch 4\n",
            "00:00:02 | Epoch 4 | Step 50/552 | NSP Loss: 0.70 | MLM Loss: 6.38 | NSP Accuracy: 33.33% | MLM Accuracy: 0.10%\n",
            "00:00:04 | Epoch 4 | Step 100/552 | NSP Loss: 0.70 | MLM Loss: 6.36 | NSP Accuracy: 41.67% | MLM Accuracy: 0.10%\n",
            "00:00:06 | Epoch 4 | Step 150/552 | NSP Loss: 0.70 | MLM Loss: 6.39 | NSP Accuracy: 33.33% | MLM Accuracy: 0.10%\n",
            "00:00:08 | Epoch 4 | Step 200/552 | NSP Loss: 0.70 | MLM Loss: 6.33 | NSP Accuracy: 45.83% | MLM Accuracy: 0.16%\n",
            "00:00:10 | Epoch 4 | Step 250/552 | NSP Loss: 0.70 | MLM Loss: 6.35 | NSP Accuracy: 50.00% | MLM Accuracy: 0.00%\n",
            "00:00:12 | Epoch 4 | Step 300/552 | NSP Loss: 0.69 | MLM Loss: 6.37 | NSP Accuracy: 54.17% | MLM Accuracy: 0.16%\n",
            "00:00:14 | Epoch 4 | Step 350/552 | NSP Loss: 0.69 | MLM Loss: 6.39 | NSP Accuracy: 54.17% | MLM Accuracy: 0.07%\n",
            "00:00:16 | Epoch 4 | Step 400/552 | NSP Loss: 0.70 | MLM Loss: 6.38 | NSP Accuracy: 62.50% | MLM Accuracy: 0.12%\n",
            "00:00:18 | Epoch 4 | Step 450/552 | NSP Loss: 0.69 | MLM Loss: 6.34 | NSP Accuracy: 45.83% | MLM Accuracy: 0.09%\n",
            "00:00:20 | Epoch 4 | Step 500/552 | NSP Loss: 0.70 | MLM Loss: 6.35 | NSP Accuracy: 33.33% | MLM Accuracy: 0.09%\n",
            "00:00:23 | Epoch 4 | Step 550/552 | NSP Loss: 0.69 | MLM Loss: 6.35 | NSP Accuracy: 62.50% | MLM Accuracy: 0.09%\n",
            "Saving model checkpoint epoch 4 to checkpoints/checkpoint_epoch4.pt\n"
          ]
        }
      ]
    }
  ]
}